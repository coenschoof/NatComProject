{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQaDu3NTvxw_"
      },
      "source": [
        "# Training a Neural Network\n",
        "We'll be training a neural network using particle swarm optimization. For this we'll be using the standard global-best PSO `pyswarms.single.GBestPSO` for optimizing the network's weights and biases.\n",
        "\n",
        "We will show the performance of training LeNet-5 using only PSO as its optimizer. As such, no gradient information is used.\n",
        "\n",
        "We will show the performance using an hour of runtime on both Fashion-MNIST and CIFAR-10, two simple benchmark datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-hiOivtsaCP"
      },
      "outputs": [],
      "source": [
        "### SETTINGS\n",
        "\n",
        "## Dataset. For convenience, comment out the one you do not wish to use.\n",
        "# --------------\n",
        "dataset_to_use = \"FashionMNIST\"\n",
        "# dataset_to_use = \"CIFAR\"\n",
        "\n",
        "\n",
        "## Runtime. Time to run PSO for, in minutes.\n",
        "# (Note: the current iteration will be completed, so technically it will always run a little longer)\n",
        "# --------------\n",
        "runtime = 1\n",
        "\n",
        "\n",
        "## PSO settings.\n",
        "# --------------\n",
        "c1 = 1.5  # personal best /cognitive parameter\n",
        "c2 = 1.5  # global best   /social parameter\n",
        "w = 0.93  # inertia\n",
        "\n",
        "num_particles = 5\n",
        "num_iterations = 100000   # Very large because the runtime setting should terminate PSO well before the number here is reached."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTWxs5UZvxxD",
        "outputId": "0041720c-16a1-4d2a-9637-1ef203050aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyswarms in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyswarms) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pyswarms) (4.64.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from pyswarms) (21.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyswarms) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyswarms) (1.21.6)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from pyswarms) (3.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from pyswarms) (3.13)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.3.1->pyswarms) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.3.1->pyswarms) (1.15.0)\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "# Import modules\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "# Import PySwarms\n",
        "!pip install pyswarms\n",
        "import pyswarms as ps\n",
        "\n",
        "# Some more magic so that the notebook will reload external python modules;\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## By default, PySwarms did not allow for time limits during PSO runs. Therefore, we modified the optimize function of the GlobalBestPSO class in this library. As a result of this modification, we can provide the maximum runtime in minutes (time)."
      ],
      "metadata": {
        "id": "cs_KMkcaHdaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual overwrite of PySwarms to print timestamps.\n",
        "\n",
        "import logging\n",
        "import datetime\n",
        "from collections import deque\n",
        "from pyswarms.base import SwarmOptimizer\n",
        "from pyswarms.utils import Reporter\n",
        "from pyswarms.backend.topology import Star\n",
        "from pyswarms.backend.operators import compute_pbest, compute_objective_function \n",
        "from pyswarms.backend.handlers import BoundaryHandler, VelocityHandler, OptionsHandler\n",
        "\n",
        "class GlobalBestPSO(SwarmOptimizer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_particles,\n",
        "        dimensions,\n",
        "        options,\n",
        "        bounds=None,\n",
        "        oh_strategy=None,\n",
        "        bh_strategy=\"periodic\",\n",
        "        velocity_clamp=None,\n",
        "        vh_strategy=\"unmodified\",\n",
        "        center=1.00,\n",
        "        ftol=-np.inf,\n",
        "        ftol_iter=1,\n",
        "        init_pos=None,\n",
        "    ):\n",
        "        \"\"\"Initialize the swarm. Modified for this particular project.\n",
        "        \"\"\"\n",
        "        super(GlobalBestPSO, self).__init__(\n",
        "            n_particles=n_particles,\n",
        "            dimensions=dimensions,\n",
        "            options=options,\n",
        "            bounds=bounds,\n",
        "            velocity_clamp=velocity_clamp,\n",
        "            center=center,\n",
        "            ftol=ftol,\n",
        "            ftol_iter=ftol_iter,\n",
        "            init_pos=init_pos,\n",
        "        )\n",
        "\n",
        "        if oh_strategy is None:\n",
        "            oh_strategy = {}\n",
        "        # Initialize logger\n",
        "        self.rep = Reporter(logger=logging.getLogger(__name__))\n",
        "        # Initialize the resettable attributes\n",
        "        self.reset()\n",
        "        # Initialize the topology\n",
        "        self.top = Star()\n",
        "        self.bh = BoundaryHandler(strategy=bh_strategy)\n",
        "        self.vh = VelocityHandler(strategy=vh_strategy)\n",
        "        self.oh = OptionsHandler(strategy=oh_strategy)\n",
        "        self.name = __name__\n",
        "\n",
        "    def optimize(\n",
        "        self, objective_func, iters, n_processes=None, verbose=True, time=None, **kwargs\n",
        "    ):\n",
        "        \"\"\"Optimize the swarm for a number of iterations, modified for this particular project.\n",
        "        \"\"\"\n",
        "\n",
        "        # Apply verbosity\n",
        "        if verbose:\n",
        "            log_level = logging.INFO\n",
        "        else:\n",
        "            log_level = logging.NOTSET\n",
        "\n",
        "        self.rep.log(\"Obj. func. args: {}\".format(kwargs), lvl=logging.DEBUG)\n",
        "        self.rep.log(\n",
        "            \"Optimize for {} iters with {}\".format(iters, self.options),\n",
        "            lvl=log_level,\n",
        "        )\n",
        "        # Populate memory of the handlers\n",
        "        self.bh.memory = self.swarm.position\n",
        "        self.vh.memory = self.swarm.position\n",
        "\n",
        "        # Setup Pool of processes for parallel evaluation\n",
        "        pool = None if n_processes is None else mp.Pool(n_processes)\n",
        "\n",
        "        self.swarm.pbest_cost = np.full(self.swarm_size[0], np.inf)\n",
        "        ftol_history = deque(maxlen=self.ftol_iter)\n",
        "\n",
        "        best_positions = []\n",
        "        # \n",
        "        if verbose == False and time != None:\n",
        "            # If provided, set the max runtime\n",
        "            endTime = datetime.datetime.now() + datetime.timedelta(minutes=time)\n",
        "\n",
        "            i = 0\n",
        "            while datetime.datetime.now() <= endTime:\n",
        "                if i%10==0:\n",
        "                  secondsLeft = (endTime - datetime.datetime.now()).seconds\n",
        "                  print(secondsLeft, \"seconds left..\")\n",
        "                  print(\"Iteration: \",i)\n",
        "                self.swarm.current_cost = compute_objective_function(self.swarm, objective_func, pool=pool, **kwargs)\n",
        "                self.swarm.pbest_pos, self.swarm.pbest_cost = compute_pbest(self.swarm)\n",
        "                # Set best_cost_yet_found for ftol\n",
        "                best_cost_yet_found = self.swarm.best_cost\n",
        "                self.swarm.best_pos, self.swarm.best_cost = self.top.compute_gbest(self.swarm)\n",
        "                best_positions.append(self.swarm.best_pos)\n",
        "                print(\"Best cost: \",round(best_cost_yet_found,3))\n",
        "                # Save to history\n",
        "                hist = self.ToHistory(\n",
        "                    best_cost=self.swarm.best_cost,\n",
        "                    mean_pbest_cost=np.mean(self.swarm.pbest_cost),\n",
        "                    mean_neighbor_cost=self.swarm.best_cost,\n",
        "                    position=self.swarm.position,\n",
        "                    velocity=self.swarm.velocity,\n",
        "                )\n",
        "                self._populate_history(hist)\n",
        "                # Verify stop criteria based on the relative acceptable cost ftol\n",
        "                relative_measure = self.ftol * (1 + np.abs(best_cost_yet_found))\n",
        "                delta = (\n",
        "                    np.abs(self.swarm.best_cost - best_cost_yet_found)\n",
        "                    < relative_measure\n",
        "                )\n",
        "                if i < self.ftol_iter:\n",
        "                    ftol_history.append(delta)\n",
        "                else:\n",
        "                    ftol_history.append(delta)\n",
        "                    if all(ftol_history):\n",
        "                        break\n",
        "                # Perform options update\n",
        "                self.swarm.options = self.oh(\n",
        "                    self.options, iternow=i, itermax=iters\n",
        "                )\n",
        "                # Perform velocity and position updates\n",
        "                self.swarm.velocity = self.top.compute_velocity(\n",
        "                    self.swarm, self.velocity_clamp, self.vh, self.bounds\n",
        "                )\n",
        "                self.swarm.position = self.top.compute_position(\n",
        "                    self.swarm, self.bounds, self.bh\n",
        "                )\n",
        "                i = i + 1\n",
        "        else:\n",
        "            print(\"Removed for this project\")\n",
        "        # Obtain the final best_cost and the final best_position\n",
        "        final_best_cost = self.swarm.best_cost.copy()\n",
        "        final_best_pos = self.swarm.pbest_pos[\n",
        "            self.swarm.pbest_cost.argmin()\n",
        "        ].copy()\n",
        "        # Write report in log and return final cost and position\n",
        "        self.rep.log(\n",
        "            \"Optimization finished | best cost: {}, best pos: {}\".format(\n",
        "                final_best_cost, final_best_pos\n",
        "            ),\n",
        "            lvl=log_level,\n",
        "        )\n",
        "        # Close Pool of Processes\n",
        "        if n_processes is not None:\n",
        "            pool.close()\n",
        "        return (final_best_cost, final_best_pos, best_positions)"
      ],
      "metadata": {
        "id": "bt9q1h8UGPql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfv8konqvxxL"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeS7SnB51ks-"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms # This import appears to be bugged, hence why we reload it in multiple cells\n",
        "\n",
        "def dataset(variant):\n",
        "  \"\"\"Loads in appropriate dataset given string.\n",
        "    Valid options are 'FashionMNIST' and 'CIFAR'.\n",
        "\n",
        "    Currently restricted to 10000 images for train and validation/test set due to runtime considerations. \n",
        "    \"\"\"\n",
        "  transformer = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "  if(variant is 'FashionMNIST'):\n",
        "    # download and create datasets\n",
        "    train_dataset = datasets.FashionMNIST(root='mnist_data', \n",
        "                                  train=True, \n",
        "                                  transform=transformer,\n",
        "                                  download=True)\n",
        "\n",
        "    valid_dataset = datasets.FashionMNIST(root='mnist_data', \n",
        "                                  train=False, \n",
        "                                  transform=transformer)\n",
        "  \n",
        "  elif(variant is 'CIFAR'):\n",
        "    train_dataset = datasets.CIFAR10(root='data', \n",
        "                               train=True, \n",
        "                               transform=transformer,\n",
        "                               download=True)\n",
        "\n",
        "    valid_dataset = datasets.CIFAR10(root='data',\n",
        "                               train=False, \n",
        "                               transform=transformer)\n",
        "  else:\n",
        "    print(\"Not a valid dataset\")\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
        "  valid_loader = DataLoader(valid_dataset, batch_size=len(valid_dataset))\n",
        "  \n",
        "  X_train = next(iter(train_loader))[0][:10000] #images\n",
        "  y_train = next(iter(train_loader))[1][:10000] #labels\n",
        "  X_valid = next(iter(valid_loader))[0][:10000] #images\n",
        "  y_valid = next(iter(valid_loader))[1][:10000] #labels\n",
        "\n",
        "  return X_train, y_train, X_valid, y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doGUwtb1Tlma"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_valid, y_valid = dataset(dataset_to_use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj2s4jv6VKqU",
        "outputId": "8acf3368-25f8-4add-8991-2fc4115e6039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO-DeWnVGR7B"
      },
      "source": [
        "# Create the Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xuc8-NWGPHh"
      },
      "outputs": [],
      "source": [
        "f_dim = 5   # filters are always 5x5\n",
        "\n",
        "# Number of filters (conv) or neurons (dense)\n",
        "conv1 = 6\n",
        "conv2 = 16\n",
        "dense1 = 120\n",
        "dense2 = 84\n",
        "\n",
        "n_classes = 10\n",
        "\n",
        "num_samples = X_train.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9AwcMSbHGvi"
      },
      "outputs": [],
      "source": [
        "# in_channels = number of channels in input data\n",
        "# dimensions = total number of weights + biases in the neural network\n",
        "\n",
        "in_channels = 0\n",
        "dimensions = 0\n",
        "if dataset_to_use is \"FashionMNIST\":\n",
        "    dimensions = 61706\n",
        "    in_channels = 1\n",
        "elif dataset_to_use is \"CIFAR\":\n",
        "    dimensions = 548878\n",
        "    in_channels = 3\n",
        "else:\n",
        "    in_channels = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2MVTnwtdIYY"
      },
      "outputs": [],
      "source": [
        "# Number of weights (Wx) per layer (biases separate (bx)):\n",
        "len_W1 = f_dim * f_dim * conv1              * in_channels * in_channels\n",
        "len_b1 = conv1                              * in_channels\n",
        "len_W2 = f_dim * f_dim * conv2 * conv1      * in_channels * in_channels\n",
        "len_b2 = conv2                              * in_channels\n",
        "len_W3 = f_dim * f_dim * conv2 * dense1     * in_channels * in_channels\n",
        "len_b3 = dense1                             * in_channels\n",
        "len_W4 = dense1 * dense2                    * in_channels * in_channels\n",
        "len_b4 = dense2                             * in_channels\n",
        "len_W5 = dense2 * n_classes                 * in_channels\n",
        "len_b5 = n_classes\n",
        "\n",
        "total_post_1 = len_W1 + len_b1\n",
        "total_post_2 = total_post_1 + len_W2 + len_b2\n",
        "total_post_3 = total_post_2 + len_W3 + len_b3\n",
        "total_post_4 = total_post_3 + len_W4 + len_b4\n",
        "total_post_5 = total_post_4 + len_W5 + len_b5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYx_o--rkPlO"
      },
      "outputs": [],
      "source": [
        "def logits_function(p, images):\n",
        "  \"\"\"Given an array of weights of the appropriate length, creates LeNet and performs a forward pass on the train data.\"\"\"\n",
        "  class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        # Reshape weight input to network size\n",
        "        W1 = p[0:len_W1].reshape((conv1*in_channels, 1 * in_channels, 5, 5))\n",
        "        W1 = torch.Tensor(W1)\n",
        "        b1 = p[len_W1:total_post_1].reshape((conv1*in_channels,))\n",
        "        b1 = torch.Tensor(b1)\n",
        "\n",
        "        W2 = p[total_post_1:(total_post_1+len_W2)].reshape((conv2*in_channels, conv1 * in_channels, 5, 5))\n",
        "        b2 = p[(total_post_1+len_W2):total_post_2].reshape((conv2 *in_channels,))\n",
        "        W2 = torch.Tensor(W2)\n",
        "        b2 = torch.Tensor(b2)\n",
        "\n",
        "        W3 = p[total_post_2:(total_post_2+len_W3)].reshape((dense1*in_channels, conv2 * in_channels, 5, 5))\n",
        "        b3 = p[(total_post_2+len_W3):total_post_3].reshape((dense1 *in_channels,))\n",
        "        W3 = torch.Tensor(W3)\n",
        "        b3 = torch.Tensor(b3)\n",
        "\n",
        "        W4 = p[total_post_3:(total_post_3+len_W4)].reshape((dense2*in_channels, dense1 * in_channels)) \n",
        "        b4 = p[(total_post_3+len_W4):total_post_4].reshape((dense2 *in_channels,))\n",
        "        W4 = torch.Tensor(W4)\n",
        "        b4 = torch.Tensor(b4)\n",
        "\n",
        "        W5 = p[total_post_4:(total_post_4+len_W5)].reshape((n_classes, dense2 * in_channels))\n",
        "        b5 = p[(total_post_4+len_W5):total_post_5].reshape((n_classes,))\n",
        "        W5 = torch.Tensor(W5)\n",
        "        b5 = torch.Tensor(b5)\n",
        "\n",
        "        # Define activation and pool operations\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.AvgPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "\n",
        "        # Define architecture and map weights\n",
        "        if dataset_to_use is \"FashionMNIST\":\n",
        "          self.conv1 = nn.Conv2d(in_channels, out_channels=conv1 * in_channels, kernel_size=(5,5),stride=(1,1),padding=(2,2))\n",
        "        elif dataset_to_use is \"CIFAR\":\n",
        "          self.conv1 = nn.Conv2d(in_channels, out_channels=conv1 * in_channels, kernel_size=(5,5),stride=(1,1),padding=(0,0))\n",
        "        else:\n",
        "          print(\"Invalid dataset, cannot determine padding.\")\n",
        "        self.conv1.weight.data = W1\n",
        "        self.conv1.bias.data = b1\n",
        "\n",
        "        self.conv2 = nn.Conv2d(conv1 * in_channels, out_channels=conv2 * in_channels, kernel_size=(5,5),stride=(1,1),padding=(0,0))\n",
        "        self.conv2.weight.data = W2\n",
        "        self.conv2.bias.data = b2\n",
        "\n",
        "        self.conv3 = nn.Conv2d(conv2 * in_channels, out_channels=dense1 * in_channels, kernel_size=(5,5),stride=(1,1),padding=(0,0))\n",
        "        self.conv3.weight.data = W3\n",
        "        self.conv3.bias.data = b3\n",
        "\n",
        "        self.linear1 = nn.Linear(dense1 * in_channels, dense2 * in_channels)\n",
        "        self.linear1.weight.data = W4\n",
        "        self.linear1.bias.data = b4\n",
        "\n",
        "        self.linear2 = nn.Linear(dense2 * in_channels, n_classes)\n",
        "        self.linear2.weight.data = W5\n",
        "        self.linear2.bias.data = b5\n",
        "    \n",
        "    def forward(self, x):\n",
        "      # Perform a forward pass of the network\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv3(x)) # num_examples x 120 x 1 x 1 --> num_examples x 120\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "  model = LeNet()\n",
        "  return model(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IctM6pLf5oY-"
      },
      "outputs": [],
      "source": [
        "# Forward propagation\n",
        "def forward_prop(params):\n",
        "    \"\"\"Computes for the forward propagation of the neural network from an array of weights and biases.\n",
        "    Returns the loss.\n",
        "    \"\"\"\n",
        "\n",
        "    logits = logits_function(params, X_train)\n",
        "\n",
        "    # Compute for the softmax of the logits\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    \n",
        "    # Compute the loss from the (softmaxed) logit probs\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    y_train_tensor = torch.tensor(y_train)\n",
        "    y_train_tensor = y_train_tensor.type(torch.LongTensor)\n",
        "    output = loss(probs, y_train_tensor)\n",
        "    \n",
        "    return output.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNJ3L72fkuwY"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    \"\"\"Forward propagation for the \n",
        "    whole swarm. Method adapted from the framework.\n",
        "    \"\"\"\n",
        "    n_particles = x.shape[0]\n",
        "    j = [forward_prop(x[i]) for i in range(n_particles)]\n",
        "    return np.array(j)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the Network"
      ],
      "metadata": {
        "id": "O5-Gb_5vGTio"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "uMskeiEQpZsW",
        "outputId": "cbe24d5b-7407-4e28-f8a7-3ece5c9c3e89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59 seconds left..\n",
            "Iteration:  0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-a6196728c455>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"# Initialize swarm\\noptions = {'c1': c1, 'c2': c2, 'w': w}\\n\\n# Call instance of PSO\\noptimizer = GlobalBestPSO(n_particles=num_particles, dimensions=dimensions, options=options)\\n\\n# Perform optimization\\n\\n#Verbose must be false for time to work\\ncost, pos, best_pos = optimizer.optimize(f, iters=num_iterations, verbose=False, time=runtime)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-11cdb31530cc>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, objective_func, iters, n_processes, verbose, time, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m                   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecondsLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds left..\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iteration: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_objective_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbest_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbest_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_pbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;31m# Set best_cost_yet_found for ftol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyswarms/backend/operators.py\u001b[0m in \u001b[0;36mcompute_objective_function\u001b[0;34m(swarm, objective_func, pool, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \"\"\"\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         results = pool.map(\n",
            "\u001b[0;32m<ipython-input-31-743f182bbdc5>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_particles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-743f182bbdc5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_particles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-37ff4ca4c999>\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Compute for the softmax of the logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: logits_function() takes 0 positional arguments but 2 were given"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Initialize swarm\n",
        "options = {'c1': c1, 'c2': c2, 'w': w}\n",
        "\n",
        "# Call instance of PSO\n",
        "optimizer = GlobalBestPSO(n_particles=num_particles, dimensions=dimensions, options=options)\n",
        "\n",
        "# Perform optimization\n",
        "# Verbose must be false for time to work\n",
        "cost, pos, best_pos = optimizer.optimize(f, iters=num_iterations, verbose=False, time=runtime)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report the Performance"
      ],
      "metadata": {
        "id": "1Q4PNfpvGYCH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4t8A8XEQ9cIP"
      },
      "outputs": [],
      "source": [
        "def predict(pos, images):\n",
        "    \"\"\"\n",
        "    Use the trained weights to perform class predictions.\n",
        "    \"\"\"\n",
        "    \n",
        "    logits = logits_function(pos, images)\n",
        "    logits = logits.detach().numpy()\n",
        "    y_pred = np.argmax(logits, axis=1)\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr5ySFOt9g2p"
      },
      "outputs": [],
      "source": [
        "print(\"Best train acc: \",max([(predict(x, X_train) == y_train.numpy()).mean() for x in best_pos]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXkfbjWNcdLH"
      },
      "outputs": [],
      "source": [
        "print(\"Best val acc: \", max([(predict(x, X_valid) == y_valid.numpy()).mean() for x in best_pos]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Experiment - PSO.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}