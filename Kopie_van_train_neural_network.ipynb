{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coenschoof/NatComProject/blob/main/Kopie_van_train_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQaDu3NTvxw_"
      },
      "source": [
        "# Training a Neural Network\n",
        "In this example, we'll be training a neural network using particle swarm optimization. For this we'll be using the standard global-best PSO `pyswarms.single.GBestPSO` for optimizing the network's weights and biases. This aims to demonstrate how the API is capable of handling custom-defined functions.\n",
        "\n",
        "For this example, we'll try to classify the three iris species in the Iris Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTWxs5UZvxxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f56037-d371-4759-adea-934bb9398755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyswarms\n",
            "  Downloading pyswarms-1.3.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▏                            | 10 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 30 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 40 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 51 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 61 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 71 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 81 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 92 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 102 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 104 kB 16.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from pyswarms) (21.4.0)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from pyswarms) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pyswarms) (4.64.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from pyswarms) (3.13)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyswarms) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyswarms) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyswarms) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.3.1->pyswarms) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.3.1->pyswarms) (1.15.0)\n",
            "Installing collected packages: pyswarms\n",
            "Successfully installed pyswarms-1.3.0\n"
          ]
        }
      ],
      "source": [
        "# Import modules\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "\n",
        "# Import PySwarms\n",
        "!pip install pyswarms\n",
        "import pyswarms as ps\n",
        "\n",
        "# Some more magic so that the notebook will reload external python modules;\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcpINbjyvxxF"
      },
      "source": [
        "First, we'll load the dataset from `scikit-learn`. The Iris Dataset contains 3 classes for each of the iris species (_iris setosa_, _iris virginica_, and _iris versicolor_). It has 50 samples per class with 150 samples in total, making it a very balanced dataset. Each sample is characterized by four features (or dimensions): sepal length, sepal width, petal length, petal width."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfv8konqvxxL"
      },
      "source": [
        "## Load the iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuUN-l63vxxL"
      },
      "outputs": [],
      "source": [
        "data = load_iris()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkJ5Sq6ivxxL"
      },
      "outputs": [],
      "source": [
        "# Store the features as X and the labels as y\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "#print(X)\n",
        "\n",
        "test = np.random.randint(5, size=(4, 20))\n",
        "#print(test)\n",
        "#print(np.shape(X), np.shape(test))\n",
        "#print(np.shape(X.dot(test)))\n",
        "\n",
        "#https://stats.stackexchange.com/questions/291680/can-any-one-explain-why-dot-product-is-used-in-neural-network-and-what-is-the-in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD_10gdOvxxN"
      },
      "source": [
        "## Constructing a custom objective function\n",
        "Recall that neural networks can simply be seen as a mapping function from one space to another. For now, we'll build a simple neural network with the following characteristics:\n",
        "* Input layer size: 4\n",
        "* Hidden layer size: 20 (activation: $\\tanh(x)$)\n",
        "* Output layer size: 3 (activation: $softmax(x)$)\n",
        "\n",
        "Things we'll do:\n",
        "1. Create a `forward_prop` method that will do forward propagation for one particle.\n",
        "2. Create an overhead objective function `f()` that will compute `forward_prop()` for the whole swarm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuWazJB7vxxO"
      },
      "source": [
        "What we'll be doing then is to create a swarm with a number of dimensions equal to the weights and biases. We will __unroll__ these parameters into an n-dimensional array, and have each particle take on different values. Thus, each particle represents a candidate neural network with its own weights and bias. When feeding back to the network, we will reconstruct the learned weights and biases. \n",
        "\n",
        "When rolling-back the parameters into weights and biases, it is useful to recall the shape and bias matrices:\n",
        "* Shape of input-to-hidden weight matrix: (4, 20)\n",
        "* Shape of input-to-hidden bias array: (20, )\n",
        "* Shape of hidden-to-output weight matrix: (20, 3)\n",
        "* Shape of hidden-to-output bias array: (3, )\n",
        "\n",
        "By unrolling them together, we have $(4 * 20) + (20 * 3) + 20 + 3 = 163$ parameters, or 163 dimensions for each particle in the swarm.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cw-4oIBvxxP"
      },
      "source": [
        "The negative log-likelihood will be used to compute for the error between the ground-truth values and the predictions. Also, because PSO doesn't rely on the gradients, we'll not be performing backpropagation (this may be a good thing or bad thing under some circumstances).\n",
        "\n",
        "Now, let's write the forward propagation procedure as our objective function. Let $X$ be the input, $z_l$ the pre-activation at layer $l$, and $a_l$ the activation for layer $l$:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhWDRAUmvxxP"
      },
      "source": [
        "## Neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPwXz9jevxxQ"
      },
      "outputs": [],
      "source": [
        "n_inputs = 4\n",
        "n_hidden = 20\n",
        "n_classes = 3\n",
        "\n",
        "num_samples = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGnyPBO6vxxQ"
      },
      "outputs": [],
      "source": [
        "def logits_function(p):\n",
        "  #input is een array van 1x163 lang die alle parameters (weights en biases) bevat\n",
        "    \"\"\" Calculate roll-back the weights and biases\n",
        "    \n",
        "    Inputs\n",
        "    ------\n",
        "    p: np.ndarray\n",
        "        The dimensions should include an unrolled version of the \n",
        "        weights and biases.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    numpy.ndarray of logits for layer 2\n",
        "    \n",
        "    \"\"\"\n",
        "    # Roll-back the weights and biases (dus van 163x3 naar W1 = 4x20, b1 = 1x20, W2 = 20x3, b2 = 1x3)\n",
        "\n",
        "    #W1: 4 rows, 20 columns\n",
        "    W1 = p[0:80].reshape((n_inputs,n_hidden))\n",
        "    #print(\"weights W1: \",W1)\n",
        "    #print(\"Shape W1\", np.shape(W1))\n",
        "    b1 = p[80:100].reshape((n_hidden,))\n",
        "    W2 = p[100:160].reshape((n_hidden,n_classes))\n",
        "    b2 = p[160:163].reshape((n_classes,))\n",
        "    \n",
        "    # Perform forward propagation (dus de gerollbackte weights en biases door het netwerk laten lopen)\n",
        "    z1 = X.dot(W1) + b1  # Pre-activation in Layer 1\n",
        "    a1 = np.tanh(z1)     # Activation in Layer 1\n",
        "    logits = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
        "\n",
        "    #output is een array van 150x3, waarbij 150 het aantal samples is, en 3 de classes.\n",
        "    return logits          # Logits for Layer 2\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brn8hvCPvxxR"
      },
      "outputs": [],
      "source": [
        "# Forward propagation\n",
        "def forward_prop(params):\n",
        "    \"\"\"Forward propagation as objective function\n",
        "    \n",
        "    This computes for the forward propagation of the neural network, as\n",
        "    well as the loss. \n",
        "    \n",
        "    Inputs\n",
        "    ------\n",
        "    params: np.ndarray\n",
        "        The dimensions should include an unrolled version of the \n",
        "        weights and biases.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        The computed negative log-likelihood loss given the parameters\n",
        "    \"\"\"\n",
        "    #print(\"params \", np.shape(params))\n",
        "    logits = logits_function(params)\n",
        "    #print(\"logit functions \", logits, np.shape(logits))\n",
        "\n",
        "\n",
        "\n",
        "    # Compute for the softmax of the logits\n",
        "    exp_scores = np.exp(logits)\n",
        "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) \n",
        "    \n",
        "    # Compute for the negative log likelihood\n",
        "\n",
        "    corect_logprobs = -np.log(probs[range(num_samples), y])\n",
        "    loss = np.sum(corect_logprobs) / num_samples\n",
        "    \n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtbDdSGTvxxR"
      },
      "source": [
        "Now that we have a method to do forward propagation for one particle (or for one set of dimensions), we can then create a higher-level method to compute `forward_prop()` to the whole swarm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oW-EEkOvxxS"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    \"\"\"Higher-level method to do forward_prop in the \n",
        "    whole swarm.\n",
        "    \n",
        "    Inputs\n",
        "    ------\n",
        "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
        "        The swarm that will perform the search\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    numpy.ndarray of shape (n_particles, )\n",
        "        The computed loss for each particle\n",
        "    \"\"\"\n",
        "    #print(\"x[i] \", np.shape(x[1]), x[1])\n",
        "    n_particles = x.shape[0]\n",
        "    j = [forward_prop(x[i]) for i in range(n_particles)]\n",
        "    return np.array(j)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP336HopvxxS"
      },
      "source": [
        "## Performing PSO on the custom-function\n",
        "Now that everything has been set-up, we just call our global-best PSO and run the optimizer as usual. For now, we'll just set the PSO parameters arbitrarily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVDErFBWvxxS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "167319d9-88d5-4f69-b0f8-23c6a39fd707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-10 14:11:42,870 - pyswarms.single.global_best - INFO - Optimize for 1000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.single.global_best:  15%|█▌        |153/1000, best_cost=0.0497\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9641943de019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# Initialize swarm\\noptions = {\\'c1\\': 0.5, \\'c2\\': 0.3, \\'w\\':0.9}\\n\\n# Call instance of PSO\\ndimensions = (n_inputs * n_hidden) + (n_hidden * n_classes) + n_hidden + n_classes\\nprint(dimensions) \\noptimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimensions, options=options)\\n\\n# Perform optimization\\n#print(\"HIER IS F\", f)\\ncost, pos = optimizer.optimize(f, iters=1000)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyswarms/single/global_best.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, objective_func, iters, n_processes, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# Compute cost for current position and personal best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;31m# fmt: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_objective_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbest_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbest_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_pbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;31m# Set best_cost_yet_found for ftol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyswarms/backend/operators.py\u001b[0m in \u001b[0;36mcompute_objective_function\u001b[0;34m(swarm, objective_func, pool, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \"\"\"\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         results = pool.map(\n",
            "\u001b[0;32m<ipython-input-10-9ee4cee0eef0>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#print(\"x[i] \", np.shape(x[1]), x[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mn_particles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-9ee4cee0eef0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#print(\"x[i] \", np.shape(x[1]), x[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mn_particles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-96feac8d60ec>\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \"\"\"\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#print(\"params \", np.shape(params))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m#print(\"logit functions \", logits, np.shape(logits))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-6c06c5d7b71a>\u001b[0m in \u001b[0;36mlogits_function\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Perform forward propagation (dus de gerollbackte weights en biases door het netwerk laten lopen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m  \u001b[0;31m# Pre-activation in Layer 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# Activation in Layer 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;31m# Pre-activation in Layer 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Initialize swarm\n",
        "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
        "\n",
        "# Call instance of PSO\n",
        "dimensions = (n_inputs * n_hidden) + (n_hidden * n_classes) + n_hidden + n_classes\n",
        "print(dimensions) \n",
        "optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimensions, options=options)\n",
        "\n",
        "# Perform optimization\n",
        "#print(\"HIER IS F\", f)\n",
        "cost, pos = optimizer.optimize(f, iters=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apSHLTWivxxT"
      },
      "source": [
        "## Checking the accuracy\n",
        "We can then check the accuracy by performing forward propagation once again to create a set of predictions. Then it's only a simple matter of matching which one's correct or not. For the `logits`, we take the `argmax`. Recall that the softmax function returns probabilities where the whole vector sums to 1. We just take the one with the highest probability then treat it as the network's prediction.\n",
        "\n",
        "Moreover, we let the best position vector found by the swarm be the weight and bias parameters of the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Hx_KBoYvxxT"
      },
      "outputs": [],
      "source": [
        "def predict(pos):\n",
        "    \"\"\"\n",
        "    Use the trained weights to perform class predictions.\n",
        "    \n",
        "    Inputs\n",
        "    ------\n",
        "    pos: numpy.ndarray\n",
        "        Position matrix found by the swarm. Will be rolled\n",
        "        into weights and biases.\n",
        "    \"\"\"\n",
        "    # Waar wordt de beste position gevonden door de swarm eigenlijk gevonden?\n",
        "    logits = logits_function(pos)\n",
        "    y_pred = np.argmax(logits, axis=1)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDztELmfvxxT"
      },
      "source": [
        "And from this we can just compute for the accuracy. We perform predictions, compare an equivalence to the ground-truth value `y`, and get the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaR_qoPUvxxU",
        "outputId": "23fc9960-45ef-416c-8f25-5aec67aeaf01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9866666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "(predict(pos) == y).mean()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Kopie van train_neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}